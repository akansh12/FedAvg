{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b6f5f5ab290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 5  #number of clients\n",
    "NUM_EPOCHS = 5   #local epochs\n",
    "BATCH_SIZE = 32  #local batch size\n",
    "LR = 0.01\n",
    "NUM_ROUNDS = 10  #number of communication rounds\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple cnn for mnist\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 1600)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple training function\n",
    "def train_epoch(model, dataloader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_correct = 0\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = train_correct / len(dataloader.dataset)\n",
    "    return model, total_loss, accuracy\n",
    "\n",
    "#simple testing function\n",
    "def test_model(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += loss_function(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = test_correct / len(dataloader.dataset)\n",
    "    return total_loss, accuracy\n",
    "\n",
    "def train(model, train_loader, test_loader, optimizer, loss_function, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, loss_function, device)\n",
    "        if test_loader:\n",
    "            test_loss, test_accuracy = test_model(model, test_loader, loss_function, device)\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}')\n",
    "            test_accuracy = 'nan'\n",
    "            test_loss = 'nan'\n",
    "    return model, train_loss, train_accuracy, test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 356.7633 - Train Accuracy: 0.9430 - Test Loss: 46.9566 - Test Accuracy: 0.9571\n",
      "Epoch 2/10 - Train Loss: 207.3113 - Train Accuracy: 0.9676 - Test Loss: 31.3497 - Test Accuracy: 0.9709\n",
      "Epoch 3/10 - Train Loss: 186.7636 - Train Accuracy: 0.9703 - Test Loss: 27.7003 - Test Accuracy: 0.9765\n",
      "Epoch 4/10 - Train Loss: 186.6661 - Train Accuracy: 0.9716 - Test Loss: 29.4968 - Test Accuracy: 0.9745\n",
      "Epoch 5/10 - Train Loss: 174.2264 - Train Accuracy: 0.9732 - Test Loss: 38.4680 - Test Accuracy: 0.9676\n",
      "Epoch 6/10 - Train Loss: 173.8800 - Train Accuracy: 0.9736 - Test Loss: 34.8001 - Test Accuracy: 0.9705\n",
      "Epoch 7/10 - Train Loss: 171.1548 - Train Accuracy: 0.9736 - Test Loss: 30.7949 - Test Accuracy: 0.9729\n",
      "Epoch 8/10 - Train Loss: 162.4146 - Train Accuracy: 0.9757 - Test Loss: 40.5097 - Test Accuracy: 0.9662\n",
      "Epoch 9/10 - Train Loss: 166.5521 - Train Accuracy: 0.9747 - Test Loss: 27.5115 - Test Accuracy: 0.9758\n",
      "Epoch 10/10 - Train Loss: 157.2287 - Train Accuracy: 0.9764 - Test Loss: 34.0378 - Test Accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "model, train_loss, train_acc, test_loss, test_acc = train(model, trainloader, testloader, optimizer, loss_function, DEVICE, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    if config[\"model\"] == \"SimpleCNN\":\n",
    "        return SimpleCNN()\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported\")\n",
    "    \n",
    "def load_data(config):\n",
    "    if config[\"dataset\"] == \"MNIST\":\n",
    "        data = datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))]))\n",
    "    else:\n",
    "        raise ValueError(\"Dataset not supported\")\n",
    "    \n",
    "    if config[\"iid\"]:\n",
    "        client_data = random_split(data, [len(data) // config['num_clients'] for _ in range(config['num_clients'])])\n",
    "    else:\n",
    "        raise ValueError(\"NOT IMPLEMENTED\")\n",
    "    return client_data\n",
    "\n",
    "def get_testloader(config):\n",
    "    if config[\"dataset\"] == \"MNIST\":\n",
    "        data = datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))]))\n",
    "    else:\n",
    "        raise ValueError(\"Dataset not supported\")\n",
    "    return torch.utils.data.DataLoader(data, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "class FedAVG():\n",
    "    def __init__(self, config) -> None:\n",
    "        self.config = config\n",
    "        self.global_model = get_model(config).to(config[\"device\"])\n",
    "        self.client_data = load_data(config)\n",
    "        self.testloader = get_testloader(config)\n",
    "\n",
    "    def client_train(self, client_id):\n",
    "        data = self.client_data[client_id]\n",
    "        model = get_model(self.config).to(self.config[\"device\"])\n",
    "        model.load_state_dict(self.global_model.state_dict())\n",
    "        optimizer = getattr(optim, self.config[\"optimizer\"])(model.parameters(), lr=self.config[\"lr\"])\n",
    "        loss_function = getattr(nn, self.config[\"loss_function\"])()\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(data, batch_size=self.config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        model, local_train_loss, local_train_accuracy, _, _ = train(model, data_loader, None, optimizer, loss_function, self.config[\"device\"], self.config[\"num_epochs\"])\n",
    "        print(f'Client {client_id} - Local Train Loss: {local_train_loss:.4f} - Local Train Accuracy: {local_train_accuracy:.4f}')\n",
    "\n",
    "        return model.state_dict()\n",
    "    \n",
    "    def aggregate(self, weights, client_sample_sizes):\n",
    "        total_samples = np.sum(client_sample_sizes)\n",
    "        avg_weights = {}\n",
    "        for key in weights[0].keys():\n",
    "            avg_weights[key] = sum(\n",
    "                weights[i][key] * (client_sample_sizes[i] / total_samples)\n",
    "                for i in range(len(weights)))\n",
    "        return avg_weights\n",
    "    \n",
    "    def run(self):\n",
    "        for round in range(self.config[\"num_rounds\"]):\n",
    "            client_weights = []\n",
    "            client_sample_sizes = []\n",
    "            selected_clients = np.random.choice(len(self.client_data), self.config[\"num_client_selection\"], replace=False)\n",
    "            for client_id in selected_clients:\n",
    "                client_weights.append(self.client_train(client_id))\n",
    "                client_sample_sizes.append(len(self.client_data[client_id]))\n",
    "            aggregated_weights = self.aggregate(client_weights, client_sample_sizes)\n",
    "            self.global_model.load_state_dict(aggregated_weights)\n",
    "            print(f\"Round {round + 1} completed\")\n",
    "            test_loss, test_accuracy = test_model(self.global_model,self.testloader, getattr(nn, self.config[\"loss_function\"])(), self.config[\"device\"])\n",
    "        return self.global_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
